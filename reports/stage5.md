### Результаты профилирования

Доля проксирования и отправки респонсов и для alloc, и для cpu выросла примерно вдвое для обоих типов запросов. Из-за того, что proxy() теперь вызывается не для каждого третьего запроса, а для всех и не по одному разу, участилась отправка запросов и формирование ответов.
**Обстрел put-ами**
Параметры: -t64 -c64 -R6000
```
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.91ms  812.61us   8.00ms   66.14%
    Req/Sec    99.34     48.93   222.00     78.23%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.83ms
 75.000%    2.47ms
 90.000%    3.03ms
 99.000%    3.91ms
 99.900%    4.88ms
 99.990%    6.00ms
 99.999%    6.93ms
100.000%    8.00ms
----------------------------------------------------------
  360034 requests in 1.00m, 23.00MB read
Requests/sec:   6001.07
Transfer/sec:    392.65KB
```
6000 запроса в секунду при обещанных 6000. Относительно предыдущего этапа ухудшения нет.

Latency 4 этапа:
```
  Latency Distribution (HdrHistogram - Recorded Latency)
   50.000%    1.62ms
   75.000%    2.23ms
   90.000%    2.82ms
   99.000%    3.68ms
   99.900%    4.38ms
   99.990%    6.37ms
   99.999%    8.98ms
  100.000%   10.37ms
```
Время выполнения запросов увеличилось на ~10%.
Причина замедления в том, что приходится проксировать запросы на несколько нод, дожидаться ответа от каждой и только потом возвращать результат.
 
ALLOC
1% - Потоки-workerы берут задачи из очереди
5% - Отправка респонса
10% - Put в DAO
19% - Выяснение ноды по ключу, murmur хэширование
21% - Чтение из сокетов
62% - Проксирование (на прошлой стадии было 39%)
[ALLOC PUT](profiling_results/allocput5.svg)

CPU
4% - Usert в DAO
4% - Отправка ответа клиенту
12% - Отправка ответа с опрашиваемых узлов для определения результата
11% - Чтение из сокетов
17% - Проксирование (вместо 8% на 4 этапе)
19% - Опрос состояния сокетов
30% - Потоки-workerы берут задачи из очереди
[CPU PUT](profiling_results/cpuput5.svg)

LOCK
45% - Потоки-workerы складывают в очередь задачи
38% - Потоки-workerы берут задачи из очереди
17% - Отправка ответа HttpSession.sendResponse
[LOCK PUT](profiling_results/lockput5.svg)

Обстрел get-ами
Параметры: -t64 -c64 -R6000
```
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.01ms  805.63us   8.23ms   65.14%
    Req/Sec    99.30     50.03   222.00     77.14%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.96ms
 75.000%    2.59ms
 90.000%    3.11ms
 99.000%    3.89ms
 99.900%    4.54ms
 99.990%    5.49ms
 99.999%    7.72ms
100.000%    8.24ms
----------------------------------------------------------
  480042 requests in 1.33m, 32.44MB read
Requests/sec:   6000.68
Transfer/sec:    415.20KB
```
6001 requests/sec из 6000 обещанных.

Latency 4 стадии:
```
 Latency Distribution (HdrHistogram - Recorded Latency)
   50.000%    1.66ms
   75.000%    2.28ms
   90.000%    2.86ms
   99.000%    3.69ms
   99.900%    4.28ms
   99.990%    5.06ms
   99.999%    6.35ms
  100.000%    7.94ms
```
Медианное время ответа выросло на 18%, а на больших персентилях, как и для PUT, увеличилось примерно на 10%. Причина, очевидно, та же - дублирование запроса на все узлы и ожидание ответов.

ALLOC
0.25% - Выбор n нод по ключу, murmur хэширование (с 14% на прошлом этапе. С многократным увеличением числа вызовов proxy() усложнение метода выбора узлов стало совсем незаметным)
1% - Потоки-workerы берут задачи из очереди
4% - Отправка ответа HttpSession.sendResponse
20% - Get из dao
27% - Чтение из сокетов
46% - Проксирование
[ALLOC GET](profiling_results/allocget5.svg)

CPU
7% - Get из dao
5% - Отправка ответа клиенту
11% - Отправка ответа с опрашиваемых узлов для определения результата
10% - Чтение из сокетов
14% - Выбор n нод по ключу, murmur хэширование
17% - Опрос состояния селекторов
18% - Проксирование (вместо 7% на 4 этапе)
29% - Потоки-workerы берут задачи из очереди
[CPU GET](profiling_results/cpuget5.svg)

LOCK
38% - Потоки-workerы берут задачи из очереди
13% - Get в dao
47% - Потоки-workerы складывают в очередь задачи
[LOCK GET](profiling_results/lockget5.svg)